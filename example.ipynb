{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "example.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFOg446dh3ki",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d643edf1-967f-49ae-a27f-1f1830277210"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CT-cXbOmhbqv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11f9bf87-521b-44f4-dfa7-1d09b269134f"
      },
      "source": [
        "%cd \"drive/My Drive/outrageclf/\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/outrageclf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EF1t_c4FyRSq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac6ffa73-afab-49a9-a2cb-96b67181386b"
      },
      "source": [
        "!python3 setup.py install"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "writing outrageclf.egg-info/PKG-INFO\n",
            "writing dependency_links to outrageclf.egg-info/dependency_links.txt\n",
            "writing requirements to outrageclf.egg-info/requires.txt\n",
            "writing top-level names to outrageclf.egg-info/top_level.txt\n",
            "reading manifest file 'outrageclf.egg-info/SOURCES.txt'\n",
            "reading manifest template 'MANIFEST.in'\n",
            "warning: no files found matching 'COPYING'\n",
            "writing manifest file 'outrageclf.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "copying outrageclf/helpers.py -> build/lib/outrageclf\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/outrageclf\n",
            "copying build/lib/outrageclf/__init__.py -> build/bdist.linux-x86_64/egg/outrageclf\n",
            "copying build/lib/outrageclf/helpers.py -> build/bdist.linux-x86_64/egg/outrageclf\n",
            "copying build/lib/outrageclf/model_architect.py -> build/bdist.linux-x86_64/egg/outrageclf\n",
            "copying build/lib/outrageclf/classifier.py -> build/bdist.linux-x86_64/egg/outrageclf\n",
            "copying build/lib/outrageclf/preprocessing.py -> build/bdist.linux-x86_64/egg/outrageclf\n",
            "byte-compiling build/bdist.linux-x86_64/egg/outrageclf/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/outrageclf/helpers.py to helpers.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/outrageclf/model_architect.py to model_architect.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/outrageclf/classifier.py to classifier.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/outrageclf/preprocessing.py to preprocessing.cpython-36.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying outrageclf.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying outrageclf.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying outrageclf.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying outrageclf.egg-info/not-zip-safe -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying outrageclf.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying outrageclf.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "creating 'dist/outrageclf-0.1.5-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing outrageclf-0.1.5-py3.6.egg\n",
            "creating /usr/local/lib/python3.6/dist-packages/outrageclf-0.1.5-py3.6.egg\n",
            "Extracting outrageclf-0.1.5-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n",
            "Adding outrageclf 0.1.5 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/outrageclf-0.1.5-py3.6.egg\n",
            "Processing dependencies for outrageclf==0.1.5\n",
            "Searching for tensorflow==2.3.0\n",
            "Best match: tensorflow 2.3.0\n",
            "Adding tensorflow 2.3.0 to easy-install.pth file\n",
            "Installing estimator_ckpt_converter script to /usr/local/bin\n",
            "Installing saved_model_cli script to /usr/local/bin\n",
            "Installing tensorboard script to /usr/local/bin\n",
            "Installing tf_upgrade_v2 script to /usr/local/bin\n",
            "Installing tflite_convert script to /usr/local/bin\n",
            "Installing toco script to /usr/local/bin\n",
            "Installing toco_from_protos script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for sklearn==0.0\n",
            "Best match: sklearn 0.0\n",
            "Adding sklearn 0.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for numpy==1.18.5\n",
            "Best match: numpy 1.18.5\n",
            "Adding numpy 1.18.5 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.6 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for nltk==3.2.5\n",
            "Best match: nltk 3.2.5\n",
            "Adding nltk 3.2.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Keras==2.4.3\n",
            "Best match: Keras 2.4.3\n",
            "Adding Keras 2.4.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for joblib==0.17.0\n",
            "Best match: joblib 0.17.0\n",
            "Adding joblib 0.17.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for emoji==0.6.0\n",
            "Best match: emoji 0.6.0\n",
            "Adding emoji 0.6.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Keras-Preprocessing==1.1.2\n",
            "Best match: Keras-Preprocessing 1.1.2\n",
            "Adding Keras-Preprocessing 1.1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for astunparse==1.6.3\n",
            "Best match: astunparse 1.6.3\n",
            "Adding astunparse 1.6.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for scipy==1.4.1\n",
            "Best match: scipy 1.4.1\n",
            "Adding scipy 1.4.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for gast==0.3.3\n",
            "Best match: gast 0.3.3\n",
            "Adding gast 0.3.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for six==1.15.0\n",
            "Best match: six 1.15.0\n",
            "Adding six 1.15.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for termcolor==1.1.0\n",
            "Best match: termcolor 1.1.0\n",
            "Adding termcolor 1.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for wheel==0.36.1\n",
            "Best match: wheel 0.36.1\n",
            "Adding wheel 0.36.1 to easy-install.pth file\n",
            "Installing wheel script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for tensorflow-estimator==2.3.0\n",
            "Best match: tensorflow-estimator 2.3.0\n",
            "Adding tensorflow-estimator 2.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for wrapt==1.12.1\n",
            "Best match: wrapt 1.12.1\n",
            "Adding wrapt 1.12.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for opt-einsum==3.3.0\n",
            "Best match: opt-einsum 3.3.0\n",
            "Adding opt-einsum 3.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for h5py==2.10.0\n",
            "Best match: h5py 2.10.0\n",
            "Adding h5py 2.10.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for google-pasta==0.2.0\n",
            "Best match: google-pasta 0.2.0\n",
            "Adding google-pasta 0.2.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for protobuf==3.12.4\n",
            "Best match: protobuf 3.12.4\n",
            "Adding protobuf 3.12.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for grpcio==1.34.0\n",
            "Best match: grpcio 1.34.0\n",
            "Adding grpcio 1.34.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for tensorboard==2.3.0\n",
            "Best match: tensorboard 2.3.0\n",
            "Adding tensorboard 2.3.0 to easy-install.pth file\n",
            "Installing tensorboard script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for absl-py==0.10.0\n",
            "Best match: absl-py 0.10.0\n",
            "Adding absl-py 0.10.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for scikit-learn==0.22.2.post1\n",
            "Best match: scikit-learn 0.22.2.post1\n",
            "Adding scikit-learn 0.22.2.post1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for PyYAML==3.13\n",
            "Best match: PyYAML 3.13\n",
            "Adding PyYAML 3.13 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for setuptools==50.3.2\n",
            "Best match: setuptools 50.3.2\n",
            "Adding setuptools 50.3.2 to easy-install.pth file\n",
            "Installing easy_install script to /usr/local/bin\n",
            "Installing easy_install-3.8 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for google-auth-oauthlib==0.4.2\n",
            "Best match: google-auth-oauthlib 0.4.2\n",
            "Adding google-auth-oauthlib 0.4.2 to easy-install.pth file\n",
            "Installing google-oauthlib-tool script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for tensorboard-plugin-wit==1.7.0\n",
            "Best match: tensorboard-plugin-wit 1.7.0\n",
            "Adding tensorboard-plugin-wit 1.7.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for google-auth==1.17.2\n",
            "Best match: google-auth 1.17.2\n",
            "Adding google-auth 1.17.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Werkzeug==1.0.1\n",
            "Best match: Werkzeug 1.0.1\n",
            "Adding Werkzeug 1.0.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for requests==2.23.0\n",
            "Best match: requests 2.23.0\n",
            "Adding requests 2.23.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Markdown==3.3.3\n",
            "Best match: Markdown 3.3.3\n",
            "Adding Markdown 3.3.3 to easy-install.pth file\n",
            "Installing markdown_py script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for requests-oauthlib==1.3.0\n",
            "Best match: requests-oauthlib 1.3.0\n",
            "Adding requests-oauthlib 1.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for pyasn1-modules==0.2.8\n",
            "Best match: pyasn1-modules 0.2.8\n",
            "Adding pyasn1-modules 0.2.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for cachetools==4.1.1\n",
            "Best match: cachetools 4.1.1\n",
            "Adding cachetools 4.1.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for rsa==4.6\n",
            "Best match: rsa 4.6\n",
            "Adding rsa 4.6 to easy-install.pth file\n",
            "Installing pyrsa-decrypt script to /usr/local/bin\n",
            "Installing pyrsa-encrypt script to /usr/local/bin\n",
            "Installing pyrsa-keygen script to /usr/local/bin\n",
            "Installing pyrsa-priv2pub script to /usr/local/bin\n",
            "Installing pyrsa-sign script to /usr/local/bin\n",
            "Installing pyrsa-verify script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for chardet==3.0.4\n",
            "Best match: chardet 3.0.4\n",
            "Adding chardet 3.0.4 to easy-install.pth file\n",
            "Installing chardetect script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for idna==2.10\n",
            "Best match: idna 2.10\n",
            "Adding idna 2.10 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for urllib3==1.24.3\n",
            "Best match: urllib3 1.24.3\n",
            "Adding urllib3 1.24.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for certifi==2020.12.5\n",
            "Best match: certifi 2020.12.5\n",
            "Adding certifi 2020.12.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for importlib-metadata==3.1.1\n",
            "Best match: importlib-metadata 3.1.1\n",
            "Adding importlib-metadata 3.1.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for oauthlib==3.1.0\n",
            "Best match: oauthlib 3.1.0\n",
            "Adding oauthlib 3.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for pyasn1==0.4.8\n",
            "Best match: pyasn1 0.4.8\n",
            "Adding pyasn1 0.4.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for zipp==3.4.0\n",
            "Best match: zipp 3.4.0\n",
            "Adding zipp 3.4.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Finished processing dependencies for outrageclf==0.1.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ku3BZxXTCHpe"
      },
      "source": [
        "**Running the wrapper function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiegrAjQCUDo"
      },
      "source": [
        "# an joblib embedding file and a model file is required\n",
        "# contact the Crockett lab for these model files\n",
        "embedding_url = \"/31k.joblib\"\n",
        "model_url = \"/31k.h5\""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMy1QJqvCtES"
      },
      "source": [
        "# these tweets are created purely for demostration\n",
        "# they are not part of, or represent any tweets in the actual training data\n",
        "tweets = [\n",
        "          \"This topic infuriates me because it violates my moral stance\",\n",
        "          \"This is just a super-normal topic #normal\",\n",
        "          \"The type of football they play today is atrocious\"\n",
        "          ]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihs24aZYCpvs",
        "outputId": "da5bf7e5-c164-413e-b4cb-aef971953ac8"
      },
      "source": [
        "from outrageclf.classifier import pretrained_model_predict\n",
        "pretrained_model_predict(tweets, embedding_url, model_url)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded pre-trained tokenizer at: 31k.joblib\n",
            "WARNING:tensorflow:Layer gru_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer gru_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer gru_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer gru_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Loaded pretrained model at: 31k.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.9660861e-01],\n",
              "       [4.0077552e-04],\n",
              "       [6.3920277e-01]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8l_1jYuDvSV"
      },
      "source": [
        "**A peak into the model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRoXZklZEE1E"
      },
      "source": [
        "This section gives you a closer look at every steps under `pretrained_model_predict`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pbnBGfRD4Zs"
      },
      "source": [
        "from outrageclf.preprocessing import WordEmbed, get_lemmatize_hashtag\n",
        "from outrageclf.classifier import _load_crockett_model"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eB07TdMrEUgN",
        "outputId": "c5e0c61b-de21-422e-b4c5-db7f41376237"
      },
      "source": [
        "# loading our pre-trained models\n",
        "word_embed = WordEmbed()\n",
        "word_embed._get_pretrained_tokenizer(embedding_url)\n",
        "model = _load_crockett_model(model_url)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded pre-trained tokenizer at: 31k.joblib\n",
            "WARNING:tensorflow:Layer gru_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer gru_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer gru_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer gru_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3En1_lLrEYtj"
      },
      "source": [
        "# the text are lemmatized and embedded into 50-d space\n",
        "lemmatized_text = get_lemmatize_hashtag(tweets)\n",
        "embedded_vector = word_embed._get_embedded_vector(lemmatized_text)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IldpZRMNEiXE",
        "outputId": "9acf3f84-2f0e-4124-b0af-6180a03b4c89"
      },
      "source": [
        "for idx, tweet in enumerate(tweets):\n",
        "  print(\"Original tweet:\", tweet)\n",
        "  print(\"Lemmatize text:\", lemmatized_text[idx])\n",
        "  print(\"50-d embedded vector:\", embedded_vector[idx])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original tweet: This topic infuriates me because it violates my moral stance\n",
            "Lemmatize text: topic infuriate violate moral stance \n",
            "50-d embedded vector: [1760 2401 1705  611 3121    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0]\n",
            "Original tweet: This is just a super-normal topic #normal\n",
            "Lemmatize text: super normal topic #normal\n",
            "50-d embedded vector: [1427 2033 1760 2033    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0]\n",
            "Original tweet: The type of football they play today is atrocious\n",
            "Lemmatize text: type football play today atrocious \n",
            "50-d embedded vector: [ 958 2308  250   93 3486    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fonhG6PW1F2G"
      },
      "source": [
        "# the model then makes prediction using the embedded_vector as inputs\n",
        "predict = model.predict(embedded_vector)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9hecInmFNe8",
        "outputId": "b71ada2e-d0d4-43c7-a911-ddbd89ac19d8"
      },
      "source": [
        "for idx, tweet in enumerate(tweets):\n",
        "  print(\"Original tweet:\", tweet)\n",
        "  print(\"Predicted probability of outrage:\", predict[idx])\n",
        "  print(\"\\n\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original tweet: This topic infuriates me because it violates my moral stance\n",
            "Predicted probability of outrage: [0.9966086]\n",
            "\n",
            "\n",
            "Original tweet: This is just a super-normal topic #normal\n",
            "Predicted probability of outrage: [0.00040078]\n",
            "\n",
            "\n",
            "Original tweet: The type of football they play today is atrocious\n",
            "Predicted probability of outrage: [0.6392028]\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}